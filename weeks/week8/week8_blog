# Week 8 Blog â€“ Amazon Hiring Bias & Data Anonymization  

In week 8 van mijn AI Ethics & Security journey heb ik mij verdiept in de **Amazon Hiring Bias case** en daarnaast een eerste versie van een **PII-anonimisatie script** gemaakt.  

---

## ğŸ“š Case Study: Amazon Hiring Bias  
Amazon gebruikte in 2014 een AI-systeem om CVâ€™s te screenen. Het model werd getraind op historische data (oude sollicitaties). Omdat in die data **voornamelijk mannen** voorkwamen, leerde het model onbedoeld dat **man zijn een voordeel was** bij selectie.  

âš ï¸ Het gevolg:  
- CVâ€™s met woorden als â€œwomenâ€™sâ€ (bijvoorbeeld *womenâ€™s chess club*) werden lager gescoord.  
- Het model bevoordeelde technische termen en hobbyâ€™s die vaker bij mannen voorkwamen.  
- Amazon moest het project uiteindelijk stopzetten.  

**Les:** Bias in trainingsdata leidt direct tot bias in AI-beslissingen. Transparantie en fairness-checks zijn noodzakelijk.  

---

## ğŸ” PII & Data Anonymization Script  
Naast de case study heb ik in Python gewerkt aan een script dat **Persoonlijk Identificeerbare Informatie (PII)** kan detecteren en vervangen.  
Voorbeeld PII:  
- Namen  
- E-mails  
- Telefoonnummers  

Met mijn script kan ik deze gegevens vervangen door **synthetische data** (bv. een nepnaam of neptelefoonnummer). Dit maakt datasets veiliger te delen voor analyse en training.  

Output:  
- **synthetic_resumes.csv** â†’ dataset met gesimuleerde CVâ€™s  
- **anonymized_resumes.csv** â†’ dataset waar PII verwijderd of vervangen is  

---

## âš–ï¸ Fairness Checks  
Tot slot heb ik een kleine fairness-analyse uitgevoerd:  
- Geslacht toegevoegd aan de dataset (M/F)  
- Model-check laten zien of er verschillen waren in voorspellingen  
- Een fairness-plot gegenereerd (*fairness_plot.png*)  

**Resultaat:** Ook in synthetische data ontstaan er ongelijkheden. Dit laat zien hoe belangrijk **bias-detectie en -correctie** is.  

---

## âœ¨ Key Insights  
- **Data = spiegel van de maatschappij** â†’ als data biased is, dan AI ook.  
- **Anonymization is niet genoeg** â†’ zelfs met geanonimiseerde data kan bias blijven bestaan.  
- **Fairness-tools** zoals plots en explainers zijn nodig om ongelijkheden zichtbaar te maken.  

---

ğŸ“‚ **Week 8 Deliverables:**  
- `Week8_Amazon_CaseStudy.md` â†’ Analyse Amazon case  
- `Week8_Notebook.ipynb` â†’ PII script + fairness checks  
- `synthetic_resumes.csv` + `anonymized_resumes.csv`  
- `fairness_plot.png`  
- `week8_blog.md` (dit bestand)  

---
