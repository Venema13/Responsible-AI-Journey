# Week 8 â€“ Data Anonymization & Fairness Check

## ğŸ“‚ File Overview
- `synthetic_resumes.csv` â†’ synthetic dataset with names, gender, education, experience  
- `anonymized_resumes.csv` â†’ anonymized dataset (PII replaced with pseudonyms)  
- `fairness_plot.png` â†’ simple fairness check (selection rate per gender)

---

## ğŸ” Anonymization Process
1. **PII removed/replaced**  
   - Names â†’ replaced with consistent pseudonyms  
   - Emails â†’ replaced with synthetic addresses  
   - Phone numbers â†’ replaced with synthetic numbers  

2. **Consistency ensured**  
   - Same name always maps to the same pseudonym  
   - Prevents accidental data leaks  

---

## ğŸ“Š Fairness Check
- A synthetic label (`selected`) was created to simulate a hiring decision.  
- **Selection rate per gender** was calculated and plotted.  

Example result:  
- Male selection rate: 58%  
- Female selection rate: 41%  
â¡ï¸ Shows how bias can appear even in synthetic or anonymized data.  

---

## ğŸ¯ Key Insights
- **Anonymization** is a critical GDPR step to reduce risks when handling personal data.  
- **Fairness checks** must always accompany anonymization â€” removing PII does not automatically remove bias.  
- **Synthetic data** is a safe way to test pipelines without exposing real candidate data.  

---
